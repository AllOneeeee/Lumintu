{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa167c0-b2af-4a0f-a8ac-92a8e7ae86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dropout, Dense \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from keras_preprocessing import sequence\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fa3d7",
   "metadata": {},
   "source": [
    "#### Normalisasi Slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e44d5b4-6bcf-46fe-b870-3b90ed39bfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kunjung prabowo resmi serah proyek bantu bersi...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anies tepuk tangan riah rektor wajib kuliah ko...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benar dukung goblok dukung ridwan kamil skema ...</td>\n",
       "      <td>Demografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anies sikap kritis kerja prabowo anggap tidak ...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anies baswedan harap polri pegang sumpah milu</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             label\n",
       "0  kunjung prabowo resmi serah proyek bantu bersi...  Sumber Daya Alam\n",
       "1  Anies tepuk tangan riah rektor wajib kuliah ko...           Politik\n",
       "2  benar dukung goblok dukung ridwan kamil skema ...         Demografi\n",
       "3  Anies sikap kritis kerja prabowo anggap tidak ...           Politik\n",
       "4      Anies baswedan harap polri pegang sumpah milu           Politik"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"train_cleaned.csv\"\n",
    "data_path = os.path.join('data')\n",
    "df = pd.read_csv(os.path.join(data_path, csv_file), delimiter=',').dropna()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # text = text.str.replace('3', 'e')\n",
    "    text = re.sub(r'3', 'e', text)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    filtered_words = [word for word in text.split()]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def preprocess_dataframe(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(lambda x: preprocess_text(x))\n",
    "    return df\n",
    "\n",
    "train_cleaned = preprocess_dataframe(df, 'text').dropna()\n",
    "\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "train_cleaned['text'] = train_cleaned['text'].apply(word_tokenize_wrapper)\n",
    "\n",
    "kamus_normalisasi = pd.read_csv(\"data/slang.csv\")\n",
    "kata_normalisasi_dict = {}\n",
    "for index, row in kamus_normalisasi.iterrows():\n",
    "    if row[0] not in kata_normalisasi_dict:\n",
    "        kata_normalisasi_dict[row[0]] = row[1] \n",
    "\n",
    "def normalisasi_kata(document):\n",
    "    normalized_words = []\n",
    "    for term in document:\n",
    "        if term in kata_normalisasi_dict:\n",
    "            normalized_term = kata_normalisasi_dict[term]\n",
    "            if pd.isna(normalized_term) or normalized_term == '':\n",
    "                # Jika hasil normalisasi adalah NaN atau kosong, tambahkan kata asli ke normalized_words\n",
    "                normalized_words.append(term)\n",
    "            else:\n",
    "                normalized_words.extend(normalized_term.split())  # Pecah hasil normalisasi dan tambahkan ke normalized_words\n",
    "        else:\n",
    "            normalized_words.append(term)\n",
    "    return ' '.join(normalized_words)\n",
    "\n",
    "train_cleaned['text'] = train_cleaned['text'].apply(normalisasi_kata)\n",
    "    # return [kata_normalisasi_dict[term] if term in kata_normalisasi_dict else term for term in document]\n",
    "\n",
    "\n",
    "train_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21255470",
   "metadata": {},
   "source": [
    "#### Stemming Hasil Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4e094da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write CSV Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kunjung prabowo resmi serah proyek bantu bersi...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anies tepuk tangan rektor wajib kuliah korupsi...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dukung goblok dukung ridwan kamil skema mayori...</td>\n",
       "      <td>Demografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anies sikap kritis kerja prabowo anggap sopan ...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anies baswedan harap polri pegang sumpah</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             label\n",
       "0  kunjung prabowo resmi serah proyek bantu bersi...  Sumber Daya Alam\n",
       "1  anies tepuk tangan rektor wajib kuliah korupsi...           Politik\n",
       "2  dukung goblok dukung ridwan kamil skema mayori...         Demografi\n",
       "3  anies sikap kritis kerja prabowo anggap sopan ...           Politik\n",
       "4           anies baswedan harap polri pegang sumpah           Politik"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_stopwords(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        stop_words = set(file.read().splitlines())\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def reduce_repeated_characters(text):\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "def preprocess_text(text, stop_words, stemmer):\n",
    "    # Lowercase \n",
    "    text = text.lower()\n",
    "    text = reduce_repeated_characters(text)\n",
    "    # Remove punctuation, '=', ',', startwith(@), word 'rt' with another character\n",
    "    text = re.sub(r\"#\\w+\", ' ', text)\n",
    "    text = re.sub(r\"\\s*[/@+]\\w+|\\brt\\b|[=,.()/:#!?'&-]\\s*|rt(?=\\W)|\\b\\w{1,4}\\b|\\[[^\\]]*\\]|(?<=\\w),(?=\\w)|https?\", ' ', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]', ' ', text)\n",
    "    text = re.sub(r'\\b(\\w+)\\d+\\b', r'\\1', text)\n",
    "    # Remove stopwords and specific word\n",
    "    filtered_words = [word for word in text.split() if word.lower() not in stop_words and word.lower()]\n",
    "    # filtered_words = ''.join(filtered_words)\n",
    "    # Stemming\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    # Join stemmed words\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, column_name, stop_words, stemmer):\n",
    "    df[column_name] = df[column_name].apply(lambda x: preprocess_text(x, stop_words, stemmer))\n",
    "    return df\n",
    "    \n",
    "\n",
    "stopwords = load_stopwords(os.path.join(data_path, 'stopwords_indonesia.txt'))\n",
    "df = train_cleaned.copy()\n",
    "train_cleaned = preprocess_dataframe(df, 'text', stopwords, stemmer).dropna()\n",
    "\n",
    "\n",
    "csv_file = \"train_cleaned_3.csv\"\n",
    "train_cleaned.to_csv(os.path.join(data_path, csv_file), index=False)\n",
    "print(\"Write CSV Done.\")\n",
    "# train_cleaned = pd.read_csv(os.path.join(data_path, csv_file), delimiter=',')\n",
    "train_cleaned.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
