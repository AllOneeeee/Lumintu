{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fa167c0-b2af-4a0f-a8ac-92a8e7ae86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dropout, Dense \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from keras_preprocessing import sequence\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e44d5b4-6bcf-46fe-b870-3b90ed39bfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kunjung prabowo resmi serah proyek bantu bersi...</td>\n",
       "      <td>Sumber Daya Alam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anies tepuk tangan riah rektor wajib kuliah ko...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benar dukung goblok dukung ridwan kamil skema ...</td>\n",
       "      <td>Demografi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anies sikap kritis kerja prabowo anggap tidak ...</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anies baswedan harap polri pegang sumpah milu</td>\n",
       "      <td>Politik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             label\n",
       "0  kunjung prabowo resmi serah proyek bantu bersi...  Sumber Daya Alam\n",
       "1  anies tepuk tangan riah rektor wajib kuliah ko...           Politik\n",
       "2  benar dukung goblok dukung ridwan kamil skema ...         Demografi\n",
       "3  anies sikap kritis kerja prabowo anggap tidak ...           Politik\n",
       "4      anies baswedan harap polri pegang sumpah milu           Politik"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"train_cleaned.csv\"\n",
    "data_path = os.path.join('data')\n",
    "df = pd.read_csv(os.path.join(data_path, csv_file), delimiter=',').dropna()\n",
    "\n",
    "# kata baku bahasa indonesia\n",
    "kata_baku = \"kamus-kata-dasar.csv\"\n",
    "df_baku = pd.read_csv(kata_baku, header=None).dropna()\n",
    "kata_baku_set = set(df_baku[0])\n",
    "kata_tidak_baku_list = []\n",
    "\n",
    "# normalisasi kata \"slang\"\n",
    "kamus_normalisasi = pd.read_csv(\"data/slang.csv\")\n",
    "kata_normalisasi_dict = {}\n",
    "for index, row in kamus_normalisasi.iterrows():\n",
    "    if row[0] not in kata_normalisasi_dict:\n",
    "        kata_normalisasi_dict[row[0]] = row[1] \n",
    "\n",
    "def preprocess_text(text):\n",
    "    # text = text.str.replace('3', 'e')\n",
    "    text = re.sub(r'3', 'e', text)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    filtered_words = [word for word in text.split()]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def preprocess_dataframe(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(lambda x: preprocess_text(x))\n",
    "    return df\n",
    "\n",
    "def normalisasi_kata(document):\n",
    "    normalized_words = [kata_normalisasi_dict.get(term, term) for term in document]\n",
    "    return ' '.join(normalized_words)\n",
    "    # return [kata_normalisasi_dict[term] if term in kata_normalisasi_dict else term for term in document]\n",
    "\n",
    "def cek_kata_baku(document):\n",
    "    kata_tidak_baku = [term for term in document if term not in kata_baku_set]\n",
    "    return kata_tidak_baku\n",
    "\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "#nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "def is_english_word(word):\n",
    "    return word in words.words()\n",
    "\n",
    "import translators as ts\n",
    "def translate_text(q_text):\n",
    "    if is_english_word(q_text):\n",
    "        hasil = ts.translate_text(q_text, from_language='en', to_language='id').lower()\n",
    "        print(f\"Translating {q_text} to {hasil}\")\n",
    "        return hasil\n",
    "    else:\n",
    "        return q_text.lower()\n",
    "\n",
    "train_cleaned = preprocess_dataframe(df, 'text').dropna()\n",
    "train_cleaned['text'] = train_cleaned['text'].apply(word_tokenize_wrapper)\n",
    "train_cleaned['text'] = train_cleaned['text'].apply(normalisasi_kata)\n",
    "train_cleaned['text'] = train_cleaned['text'].apply(word_tokenize_wrapper)\n",
    "\n",
    "# Check for non-baku words\n",
    "kata_tidak_baku = train_cleaned['text'].apply(cek_kata_baku)\n",
    "for kata in kata_tidak_baku:\n",
    "    kata_tidak_baku_list.extend(kata)\n",
    "\n",
    "train_cleaned['text'] = train_cleaned['text'].apply(lambda x: ' '.join(x))\n",
    "train_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a620c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"train_cleaned_2.csv\"\n",
    "train_cleaned.to_csv(os.path.join(data_path, csv_file), index=False)\n",
    "print(\"Write CSV Done.\")\n",
    "\n",
    "df_kata_tidak_baku = pd.DataFrame(list(set(kata_tidak_baku_list)), columns=[\"Kata Tidak Baku\"])\n",
    "df_kata_tidak_baku['Terjemahan'] = df_kata_tidak_baku.applymap(translate_text)\n",
    "df_kata_tidak_baku.to_csv(\"kata_tidak_baku.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f9323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kata Tidak Baku</th>\n",
       "      <th>Terjemahan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buzzer</td>\n",
       "      <td>bel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leading</td>\n",
       "      <td>terkemuka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polybag</td>\n",
       "      <td>polybag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purwakarta</td>\n",
       "      <td>purwakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resources</td>\n",
       "      <td>resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>tenggelamkan</td>\n",
       "      <td>tenggelamkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>dissing</td>\n",
       "      <td>dissing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>newsweek</td>\n",
       "      <td>newsweek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>sprotiv</td>\n",
       "      <td>sprotiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>about</td>\n",
       "      <td>sekitar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kata Tidak Baku    Terjemahan\n",
       "0             buzzer           bel\n",
       "1            leading     terkemuka\n",
       "2            polybag       polybag\n",
       "3         purwakarta    purwakarta\n",
       "4          resources     resources\n",
       "...              ...           ...\n",
       "3354    tenggelamkan  tenggelamkan\n",
       "3355         dissing       dissing\n",
       "3356        newsweek      newsweek\n",
       "3357         sprotiv       sprotiv\n",
       "3358           about       sekitar\n",
       "\n",
       "[3359 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kata_tidak_baku"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
